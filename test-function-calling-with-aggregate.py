from models import QueryWithAggregation, IntAggregation, TextAggregation, BooleanAggregation
from models import Tool, Function, Parameters, ParameterProperty
from weaviate_fc_utils import get_collections_info
from lm import LMService
from pydantic import BaseModel
from typing import Optional, Any

import json
import requests
import time

class AggregateQueryResult(BaseModel):
    query: str
    database_schema: dict
    metadata: str
    property_name: str 
    metrics: str
    predicted_aggregation: Optional[str]
    is_correct: bool

class ExperimentResults(BaseModel):
    total_queries: int
    correct_predictions: int
    accuracy: float
    results: list[AggregateQueryResult]

# Load synthetic filter queries generated by generate-filter-queries.py
with open("./data/synthetic-aggregation-queries.json", "r") as json_file:
    aggregation_queries_raw = json.load(json_file)
    aggregation_queries = []
    for query in aggregation_queries_raw:
        # Parse database schema from string back to dict if needed
        database_schema = query["database_schema"]
        if isinstance(database_schema, str):
            database_schema = json.loads(database_schema)
        

        # Create the appropriate aggregation object based on metadata
        if query["metadata"] == "INT AGGREGATION":
            aggregation_obj = IntAggregation(
                property_name=query["property_name"],
                metrics=query["metrics"]
            )
        elif query["metadata"] == "TEXT AGGREGATION":
            aggregation_obj = TextAggregation(
                property_name=query["property_name"], 
                metrics=query["metrics"]
            )
        elif query["metadata"] == "BOOLEAN AGGREGATION":
            aggregation_obj = BooleanAggregation(
                property_name=query["property_name"],
                metrics=query["metrics"]
            )
            
        # Create QueryWithAggregation object
        aggregation_queries.append(
            QueryWithAggregation(
                database_schema=database_schema,
                gold_collection=database_schema["weaviate_collections"][0]["name"],
                gold_aggregation=aggregation_obj,
                synthetic_query=query["query"]
            )
        )

# Weaviate Function Calling Setup

import weaviate
weaviate_client = weaviate.connect_to_local()
url = "http://localhost:8080/v1/schema"

openai_api_key = ""

lm_service = LMService(
    model_provider = "openai",
    model_name = "gpt-4o",
    api_key = openai_api_key
)

correct_counter = 0
experiment_results = []

for idx, aggregation_query in enumerate(aggregation_queries):
    # Reset collections currently defined in the Weaviate instance
    weaviate_client.collections.delete_all()
    
    # Get schema and create collections with a post requests to Weaviate
    class_schemas = aggregation_query.database_schema["weaviate_collections"]
    for class_schema in class_schemas:
        clean_schema = {
            'class': class_schema['name'],  # Use existing 'class' field
            'description': class_schema.get('description', ''),
            'properties': [
                {
                    'name': prop['name'],
                    'description': prop.get('description', ''),
                    'dataType': prop['data_type']  # Weaviate expects dataType, not data_type
                }
                for prop in class_schema.get('properties', [])
            ],
            'vectorizer': class_schema.get('vectorizer', 'text2vec-transformers'),
            'vectorIndexType': class_schema.get('vectorIndexType', 'hnsw'),
        }
        schema_str = json.dumps(clean_schema) # Note, this shouldn't be necessary, but oh well
        requests.post(
            url,
            data=schema_str,
            headers={'Content-Type': 'application/json'}
        )

    time.sleep(10) # give Weaviate 10 seconds to create the collections

    # build function from schemas
    collections_description, collections_list = get_collections_info(weaviate_client)

    # Create tool with `collections_list`
    tools = [Tool(
        type="function",
        function=Function(
            name="query_database",
            description=f"""Query a database.

            Available collections in this database:
            {collections_description}""",
            parameters=Parameters(
                type="object",
                properties={
                    "collection_name": ParameterProperty(
                        type="string",
                        description="The collection to query",
                        enum=collections_list
                    ),
                    "search_query": ParameterProperty(
                        type="string",
                        description="Optional search query to find semantically relevant items."
                    ),
                    "filter_string": ParameterProperty(
                        type="string",
                        description="""
                        Optional filter expression using prefix notation to ensure unambiguous order of operations.
                        
                        Basic condition syntax: property_name:operator:value
                        
                        Compound expressions use prefix AND/OR with parentheses:
                        - AND(condition1, condition2)
                        - OR(condition1, condition2)
                        - AND(condition1, OR(condition2, condition3))
                        
                        Examples:
                        - Simple: age:>:25
                        - Compound: AND(age:>:25, price:<:1000)
                        - Complex: OR(AND(age:>:25, price:<:1000), category:=:'electronics')
                        - Nested: AND(status:=:'active', OR(price:<:50, AND(rating:>:4, stock:>:100)))
                        
                        Supported operators:
                        - Comparison: =, >, <, >=, <= 
                        - Text only: LIKE

                        IMPORTANT!!! Please review the collection schema to make sure the property name is spelled correctly!! THIS IS VERY IMPORTANT!!!
                        """
                    ),
                    "aggregate_string": ParameterProperty(
                        type="string",
                        description="""
                        Optional aggregate expression

                        Basic property aggregation syntax: property_name:aggregation_type

                        Group by syntax: GROUP_BY(property_name)
                        - Note: Currently limited to one property or cross-reference. Nested paths are not supported.

                        Available Aggregation Types
                        Based on data type:

                        Text Properties
                        - COUNT
                        - TYPE
                        - TOP_OCCURRENCES[limit] - Optional limit parameter for minimum count

                        Numeric Properties (Number/Integer)
                        - COUNT
                        - TYPE
                        - MIN
                        - MAX
                        - MEAN
                        - MEDIAN
                        - MODE
                        - SUM

                        Boolean Properties
                        - COUNT
                        - TYPE
                        - TOTAL_TRUE
                        - TOTAL_FALSE
                        - PERCENTAGE_TRUE
                        - PERCENTAGE_FALSE

                        Date Properties
                        - COUNT
                        - TYPE
                        - MIN
                        - MAX
                        - MEAN
                        - MEDIAN
                        - MODE

                        Examples

                        Simple Aggregations

                        # Count all records in the collection
                        Article:COUNT

                        # Get wordCount (TEXT property) statistics
                        wordCount:COUNT,wordCount:MEAN,wordCount:MAX

                        # Get top occurrences of categories (TEXT property) with minimum count of 5
                        category:TOP_OCCURRENCES[5]

                        Grouped Aggregations

                        # Group by publication and get counts
                        GROUP_BY(publication):COUNT

                        # Group by category with multiple metrics
                        GROUP_BY(category):COUNT,price:MEAN,price:MAX

                        ## Combining Multiple Aggregations
                        Multiple aggregations can be combined using comma separation:

                        GROUP_BY(publication):COUNT,wordCount:MEAN,category:TOP_OCCURRENCES[5]
                        """
                    )
                },
                required=["collection_name"]
            )
        )
    )]

    prompt = "Answer the question. Use the provided tools to gain additional context."
    prompt += f"\nuser query: {aggregation_query.synthetic_query}"

    response = lm_service.one_step_function_selection_test(
        prompt=prompt,
        tools=tools
    ).choices[0].message

    print("\033[96m\nTesting with query:\033[0m")
    print(aggregation_query.synthetic_query)

    # Convert the gold aggregation into an aggregation string based on its type
    if isinstance(aggregation_query.gold_aggregation, IntAggregation):
        gold_aggregation_str = f"{aggregation_query.gold_aggregation.property_name}:{aggregation_query.gold_aggregation.metrics}"
    elif isinstance(aggregation_query.gold_aggregation, TextAggregation):
        if aggregation_query.gold_aggregation.metrics == "TOP_OCCURRENCES" and aggregation_query.gold_aggregation.top_occurrences_limit:
            gold_aggregation_str = f"{aggregation_query.gold_aggregation.property_name}:{aggregation_query.gold_aggregation.metrics}[{aggregation_query.gold_aggregation.top_occurrences_limit}]"
        else:
            gold_aggregation_str = f"{aggregation_query.gold_aggregation.property_name}:{aggregation_query.gold_aggregation.metrics}"
    elif isinstance(aggregation_query.gold_aggregation, BooleanAggregation):
        gold_aggregation_str = f"{aggregation_query.gold_aggregation.property_name}:{aggregation_query.gold_aggregation.metrics}"
    print("\033[96mGold Aggregation:\033[0m")
    print(gold_aggregation_str)
    print("\033[96mGold collection:\033[0m")
    print(aggregation_query.gold_collection)

    predicted_collection, predicted_aggregation = None, None
    is_correct = False
    
    if "tool_calls" in response.model_dump().keys():
        print("\033[96mLLM-selected collection:\033[0m")
        print(f"\033[92mCalling {len(response.tool_calls)} functions.\033[0m") # save this somewhere
        for tool_call in response.tool_calls:
            arguments_json = json.loads(tool_call.function.arguments)
            print("Function Calling Arguments:")
            print(arguments_json)
            print("With Aggregation:")
            if "aggregate_string" in arguments_json.keys():
                print(arguments_json["aggregate_string"])
                predicted_aggregation = arguments_json["aggregate_string"]
                predicted_aggregation = predicted_aggregation[0].upper() + predicted_aggregation[1:]
                if predicted_aggregation == gold_aggregation_str: 
                    correct_counter += 1
                    is_correct = True
                    break # stop looping through these tool_calls (it might call the same correct collection with 2 or more queries, etc.)
            else:
                print("No aggregation selected.")
    else:
        print("\033[96mThe LLM didn't call a function.\033[0m")

    print(f"\033[92mCurrent success rate: {(correct_counter / (idx + 1)) * 100}\033[0m")
    result = AggregateQueryResult(
        query=aggregation_query.synthetic_query,
        database_schema=aggregation_query.database_schema,
        metadata=str(type(aggregation_query.gold_aggregation)),
        property_name=aggregation_query.gold_aggregation.property_name,
        metrics=aggregation_query.gold_aggregation.metrics,
        predicted_aggregation=predicted_aggregation,
        is_correct=is_correct
    )
    experiment_results.append(result)

final_results = ExperimentResults(
    total_queries=len(experiment_results),
    correct_predictions=correct_counter,
    accuracy=correct_counter / len(experiment_results) if experiment_results else 0,
    results=experiment_results
)

# Save results to JSON file
with open("aggregation-query-results.json", "w") as f:
    json.dump(final_results.model_dump(), f, indent=2)

weaviate_client.close()
